# About



<h1><center> <img  src="https://github.com/firmai/random-assets-two/raw/master/labs/3dgifmaker30.gif" width="28" height="24" style="float:left;">  <strong><font color="#58748B">Agent</font> <font color="grey">Trading</font> </center></h1></strong>

| <a href="https://github.com/firmai/machine-learning-asset-management"><h3 ><center>  <font color="black" size=3>  GitHub</font></center></h3></a> | <a href="https://jfds.pm-research.com/content/2/1/10"><h3 ><center><font color="black" size=3>JFDS</font></center></h3></a> | <a href="mailto:dsnow@live.com"><h3 ><center><font color="black" size=3>Contact</font> </center></h3></a> |
| --- | --- | --- |

<br>



---------

<br>
<center><font face="Lucida Sans Unicode" color="#58748B" size=6><strong><sup>Reinforcement Learning Practical Trading Examples</sup></strong></font></center>



<br>

<table>
  <tr>

  </tr>
  <tr>
    <td><table>
  <tr>
    <td><a href="#prediction_head"> <center><img width="190" height="190" src="https://github.com/firmai/random-assets-two/raw/master/labs/blackboard.png"> </center>  <a/></td>
  </tr>
  <tr>
    <td ><center><h3  > Algorithms </h3></center>  </td>
  </tr>
  <tr>
    <td ><a href="#prediction_head" ><button  > Our first step is to identify</br> what type of reinforcement learning algorithms </br>
    we want our trading agents to use. </button> </a> </td>
  </tr>
</table> </td>
<td><table>
  <tr>
    <td><a href="#synth_head"> <center><img width="190" height="190" src="https://github.com/firmai/random-assets-two/raw/master/labs/data-spider.png"> </center>  <a/></td>
  </tr>
  <tr>
    <td ><center><h3  > Environment </h3></center>  </td>
  </tr>
  <tr>
    <td ><a href="#synth" ><button > Secondly we want to specify the </br> environment and the constraints imposed</br>on the trading agents.</button> </a> </td>
  </tr>
</table> </td>

<td><table>
  <tr>
    <td><a href="#vis_head"> <center><img width="190" height="190" src="https://github.com/firmai/random-assets-two/raw/master/labs/business-and-finance.png"> </center>  <a/></td>
  </tr>
  <tr>
    <td ><center><h3  > Learning </h3></center>  </td>
  </tr>
  <tr>
    <td ><a href="#vis_head" ><button > The agent is then asked to interact with  </br>the environment to learn a strategy or policy </br> that maximises some reward function. </button> </a> </td>
  </tr>
</table> </td>

<td><table>
  <tr>
    <td><a href="#misc_head"> <center><img width="190" height="190" src="https://github.com/firmai/random-assets-two/raw/master/labs/data.png"> </center>  <a/></td>
  </tr>
  <tr>
    <td ><center><h3  > Performance </h3></center>  </td>
  </tr>
  <tr>
    <td ><a href="#misc_head" ><button > The strategy's performance can be</br> measured on the historical data in a</br> simulated environment or in the market.</button> </a> </td>
  </tr>
</table> </td>
  </tr>

</table> 

<br>
<br>




<font size=5><em>M</em></font>athematical equations like the trusty $ROC$ formula
$
\frac{\text {Net Profit (annual)}}{\text { Tot. Capital Invested }}
$ provides companies with empirical markers to guide thoughtful financial decision making in, for example, capital budgeting and allocation. This measure remains a statistics for as long as it is not used in a supervised learning model, at which point it becomes a feature.

<img src="https://github.com/firmai/random-assets-two/raw/master/labs/Mountain_blreal2.png" align="center" width="400"/>
$
z=f(b+x \cdot w)=f\left(b+\sum_{i=1}^{n} x_{i} w_{i}\right)
$

Soon enough, companies realise that their statistics and predictive models remain a few steps removed from the actual decisions being made. These companies have experimented with different ways to leverage the data and prediction outputs in order to develop end-to-end automation systems. 

Historically decisions were made by combining statistics and predictions with management intuition, with simple If-Then-Else logic, or with mathematical optimisation techniques. These methods are rule-based and are generally static and hard-coded.  Back in the day this was referred to as expert systems. However, recently computers started to self-learn what decisions are optimal, removing the intermediary step of recording data and making predictions, and this is called reinforcement learning. 

<img src="https://docs.google.com/drawings/d/e/2PACX-1vQQYvxX9VBU45Oh1rP2v5SirKBrRcKmUonOvM_0mqHCVemxLh6ofPc-YA5RUtKHV4t0WQEvUUR2ByhK/pub?w=2043&amp;h=896">







